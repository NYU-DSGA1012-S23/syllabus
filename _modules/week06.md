---
title: Week 6, Feb. 28/Mar. 2
---

### Basic Techniques 3: In-Context Adaptation

We take the idea of transfer learning a step further with _in-context adaptation_. In this approach, tasks are performed
by large, general-purpose language models by having them auto-complete a prompt that describes the task and the input.
There is no fine-tuning or other explicit training on the target task.

Topics
: Language modeling, perplexity, the noisy channel model, in-context adaptation, reinforcement learning from human 
feedback, the GPT models (GPT-2, GPT-3, 
InstructGPT, ChatGPT)

Lecture
: [Slides](https://drive.google.com/file/d/1KNJvUnZGiSrCEFAw4bPOaDTziv6jf2_K/view?usp=share_link),
[Zoom Recording](https://nyu.zoom.us/rec/share/m5Vd5HVifEhOSjjpvpL15OScctCxq9pd9kmbluUfl-FW-VN9c6OXYqA2IPJC2hYU.NIj0FGE-gt75xKHt)

Lab
: [Slides](https://drive.google.com/file/d/1tbAms33Kiz7zH81lvkc9ugeVaUXzu2e0/view?usp=share_link),
[Zoom Recording](https://nyu.zoom.us/rec/share/xK1BzYJEEHwBqxqAF8LjzFS6jgZiQABaN3VUr_egcUXmD_OBBYPQEe4Yudqr6Uap.JzT8ho940HeDYJki)

Reading
: [Radford et al. (2019)](https://openai.com/blog/better-language-models/), Better Language Models and Their
Implications (blog post)
: [Lowe and Leike (2022)](https://openai.com/research/instruction-following), Aligning Language Models to Follow 
Instructions (blog post)
: [Brown et al. (2020)](https://arxiv.org/abs/2005.14165), in-context adaptation with GPT-3 (Read sections 1, 2, 
and 4, and pick two 
subsections of section 3 to read)
: [Wei et al. (2022)](https://arxiv.org/abs/2201.11903), chain-of-thought prompting
: [Press et al. (2022)](https://arxiv.org/abs/2210.03350), self-ask prompting
: [Ouyang et al. (2022)](https://arxiv.org/abs/2203.02155), reinforcement learning from human feedback (RLHF), the 
fine-tuning technique for InstructGPT and ChatGPT


Deadlines
: **HW 2 Due 2/27**{: .label .label-red } **EC 2 Due 2/27**{: .label .label-green }
<!-- : **Project Mini-Proposal Due**{: .label .label-blue } -->