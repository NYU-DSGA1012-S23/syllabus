---
title: Week 5, Feb. 21/23
---

### Guest Lecture: Working With Pretrained Models

This is a guest lecture by NYU graduate student Jason Phang, who will teach us how to fine-tune pre-trained models 
using parallel computation on GPUs.

Topics
: Fine-tuning, GPUs, high-performance computing

Readings
: **SLP**{: .label .label-yellow } [Chapter 11](https://web.stanford.edu/~jurafsky/slp3/11.pdf), on fine-tuning 
: **D2L**{: .label .label-yellow }  
[Sections 16.6â€“16.7](https://d2l.ai/chapter_natural-language-processing-applications/finetuning-bert.html), on 
fine-tuning BERT
: [Ruder (2019)](https://ruder.io/state-of-transfer-learning-in-nlp/), The State of Transfer Learning in NLP (blog post)

Deadlines
: **HW 2 Due**{: .label .label-red }
: **EC 2 Due**{: .label .label-green }