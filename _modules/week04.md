---
title: Week 4, Feb. 14/16
---

### Basic Techniques 2: Transfer Learning

We introduce _transfer learning_, a technique where large quantities of unlabeled data can be leveraged by 
pre-training an encoder network on a language modeling objective. We survey common pre-trained models such as BERT 
and GPT-2.

Topics
: Pre-trained models, fine-tuning, BERT

Reading
: [Devlin et al. (2019)](https://aclanthology.org/N19-1423/), the original BERT paper