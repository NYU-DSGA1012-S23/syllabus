---
title: Week 3, Feb. 7/9
---

### Basic Techniques 1: Deep Learning

We will learn how to define, train, and test a deep neural network model using the backpropagation and stochastic
gradient descent algorithms. We will introduce common neural network architectures in NLU such as the multi-layer
perceptron, the recurrent neural network, and the Transformer.

Topics
: Neural architectures (MLP, RNN, LSTM, Transformer), automatic differentiation, the PyTorch software package, 
hyperparameter tuning

Reading
: [Preferred Networks, Inc. (2021)](https://pytorch.org/blog/overview-of-pytorch-autograd-engine), Overview of 
PyTorch Autograd Engine (blog post)
: [Olah (2015)](https://colah.github.io/posts/2015-08-Understanding-LSTMs/), Understanding LSTM Networks (blog post)
: [Alammar (2018)](https://jalammar.github.io/illustrated-transformer/), The Illustrated Transformer (blog post)

Deadlines
: **HW 1 Due**{: .label .label-red }
: **EC 1 Due**{: .label .label-green }