---
title: Week 1, Jan. 24/26
---

### What Is Meaning?

We will introduce the concept of meaning in natural language, taking inspiration from linguists, philosophers, and data
scientists. We will learn about the word2vec model of semantics and examine in what sense and to what extent it models
"meaning."

Topics
: Lexical semantics, word embeddings, tokenization

Reading
: [Bender (2013)](https://www.morganclaypool.com/doi/abs/10.2200/S00493ED1V01Y201303HLT020) #7–16, on the concept of a "
word"
: [Bender and Lascarides (2019)](https://www.morganclaypool.com/doi/abs/10.2200/S00935ED1V02Y201907HLT043) #18, #19,

# 22–30, on lexical semantics

: [Hao (2021)](https://drive.google.com/file/d/1meO5SpD3PaQaGEZ4pYu27n0xyEncFoOK/view?usp=share_link), Sophie's notes on
vector semantics (This was written when Sophie was a grad student, so please excuse the references to Yale and New Haven
pizza.)
: [Mikolov et al. (2013)](https://arxiv.org/abs/1301.3781), the word2vec models (Optional; this may be difficult to read
since it was written a long time ago)
: [Levy and Goldberg (2014)](https://papers.nips.cc/paper/2014/hash/feab05aa91085b7a8012516bc3533958-Abstract.html),
what word2vec is really doing
