---
title: Week 1, Jan. 24/26
---

### What Is Meaning?

We will introduce the concept of meaning in natural language, taking inspiration from linguists, philosophers, and data
scientists. We will learn about the word2vec model of semantics and examine in what sense and to what extent it models
"meaning."

Topics
: Lexical semantics, word embeddings, tokenization

Reading
: **Ling1**{: .label .label-yellow } [\#7–16](https://www.morganclaypool.com/doi/abs/10.2200/S00493ED1V01Y201303HLT020),
on the concept of a “word”
: **Ling2**{: .label .label-yellow }
[\#18–19, \#21–24](https://www.morganclaypool.com/doi/abs/10.2200/S00935ED1V02Y201907HLT043), on lexical semantics
: **Notes**{: .label .label-yellow }
[on vector semantics](https://drive.google.com/file/d/16vWNLaCFEmnW2kxhsCGkd5OXPEMgKl7v/view?usp=share_link)
(skip-gram with negative sampling)
: **D2L**{: .label .label-yellow }
[Sections 15.1, 15.5–15.7](https://d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html), on various 
word
embedding models
: [Bolukbasi et al. (2016)](https://arxiv.org/abs/1607.06520), on manipulating word embeddings